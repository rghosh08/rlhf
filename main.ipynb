{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeuxunSR4S_9"
      },
      "source": [
        "# RLHF Training Loop\n",
        "\n",
        "This notebook presents a step-by-step implementation of a RLHF loop.\n",
        "\n",
        "* Policy network: GPT-2 model\n",
        "* Reward network: DistilBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08IJe4VG5Cxw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
        "from trl.core import LengthSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEQFXWHPDa9u"
      },
      "outputs": [],
      "source": [
        "config = PPOConfig(\n",
        "    model_name=\"lvwerra/gpt2-imdb\",\n",
        "    learning_rate=1.41e-5,\n",
        "    log_with=\"wandb\",\n",
        ")\n",
        "\n",
        "sent_kwargs = {\"return_all_scores\": True, \"function_to_apply\": \"none\", \"batch_size\": 16}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "gsVd_-phDgvn",
        "outputId": "b53d2b34-716b-447a-9428-0ce5bf1f7499"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231025_225926-izekkgk2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rajat-ghosh/uncategorized/runs/izekkgk2' target=\"_blank\">soft-glade-7</a></strong> to <a href='https://wandb.ai/rajat-ghosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/rajat-ghosh/uncategorized' target=\"_blank\">https://wandb.ai/rajat-ghosh/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/rajat-ghosh/uncategorized/runs/izekkgk2' target=\"_blank\">https://wandb.ai/rajat-ghosh/uncategorized/runs/izekkgk2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rajat-ghosh/uncategorized/runs/izekkgk2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f942fe461d0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOiSluo3EbrN"
      },
      "source": [
        "# Load data and models\n",
        "\n",
        "## Load IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v6R5AZGDj0l"
      },
      "outputs": [],
      "source": [
        "def build_dataset(config, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
        "    \"\"\"\n",
        "    Build dataset for training.\n",
        "\n",
        "    Args:\n",
        "        dataset_name (`str`):\n",
        "            The name of the dataset to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        dataloader (`torch.utils.data.DataLoader`):\n",
        "            The dataloader for the dataset.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    # load imdb with datasets\n",
        "    ds = load_dataset(dataset_name, split=\"train\")\n",
        "    ds = ds.rename_columns({\"text\": \"review\"})\n",
        "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
        "\n",
        "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
        "\n",
        "    def tokenize(sample):\n",
        "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
        "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "        return sample\n",
        "\n",
        "    ds = ds.map(tokenize, batched=False)\n",
        "    ds.set_format(type=\"torch\")\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "981v8aJJFn-7"
      },
      "outputs": [],
      "source": [
        "dataset = build_dataset(config)\n",
        "\n",
        "\n",
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwlK4pRwFqzp"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
        "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpCjuly2HDas"
      },
      "outputs": [],
      "source": [
        "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=dataset, data_collator=collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rPoSReSHIxy"
      },
      "outputs": [],
      "source": [
        "device = ppo_trainer.accelerator.device\n",
        "if ppo_trainer.accelerator.num_processes == 1:\n",
        "    device = 0 if torch.cuda.is_available() else \"cpu\"  # to avoid a `pipeline` bug\n",
        "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"lvwerra/distilbert-imdb\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCRsHu9VHgfR"
      },
      "source": [
        "# Generation settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AGWH7nNHUfo"
      },
      "outputs": [],
      "source": [
        "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7CQMss5HnMl"
      },
      "source": [
        "# Optimize model\n",
        "\n",
        "## Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3fDe4rzHwE7"
      },
      "source": [
        "The training loop consists of the following main steps:\n",
        "\n",
        "Get the query responses from the policy network (GPT-2)\n",
        "Get sentiments for query/responses from BERT\n",
        "Optimize policy with PPO using the (query, response, reward) triplet\n",
        "Training time\n",
        "\n",
        "This step takes ~2h on a V100 GPU with the above specified settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXLIo3JIHl8W"
      },
      "outputs": [],
      "source": [
        "output_min_length = 4\n",
        "output_max_length = 16\n",
        "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
        "\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "}\n",
        "\n",
        "\n",
        "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "    query_tensors = batch[\"input_ids\"]\n",
        "\n",
        "    #### Get response from gpt2\n",
        "    response_tensors = []\n",
        "    for query in query_tensors:\n",
        "        gen_len = output_length_sampler()\n",
        "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
        "        response_tensors.append(response.squeeze()[-gen_len:])\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "    #### Compute sentiment score\n",
        "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
        "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
        "\n",
        "    #### Run PPO step\n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "    ppo_trainer.log_stats(stats, batch, rewards)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Performance Analysis\n",
        "\n",
        "* Here we are analyzing the differences in reward from GPT-2 response before and after the PPO loop. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z_pMrIrHu4q"
      },
      "outputs": [],
      "source": [
        "#### get a batch from the dataset\n",
        "bs = 16\n",
        "game_data = dict()\n",
        "dataset.set_format(\"pandas\")\n",
        "df_batch = dataset[:].sample(bs)\n",
        "game_data[\"query\"] = df_batch[\"query\"].tolist()\n",
        "query_tensors = df_batch[\"input_ids\"].tolist()\n",
        "\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "\n",
        "#### get response from gpt2 and gpt2_ref\n",
        "for i in range(bs):\n",
        "    gen_len = output_length_sampler()\n",
        "    output = ref_model.generate(\n",
        "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    response_tensors_ref.append(output)\n",
        "    output = model.generate(\n",
        "        torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs\n",
        "    ).squeeze()[-gen_len:]\n",
        "    response_tensors.append(output)\n",
        "\n",
        "#### decode responses\n",
        "game_data[\"response (before)\"] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
        "game_data[\"response (after)\"] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
        "\n",
        "#### sentiment analysis of query/response pairs before/after\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (before)\"])]\n",
        "game_data[\"rewards (before)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "texts = [q + r for q, r in zip(game_data[\"query\"], game_data[\"response (after)\"])]\n",
        "game_data[\"rewards (after)\"] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "# store results in a dataframe\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubKTo8iNJjLi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
